---
title: "XLK Stock Machine Learning"
author: "Andre Contreras"
date: "2024-05-13"
output: prettydoc::html_pretty
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(readr)
library(Metrics)
library(dplyr)
library(zoo)
library(ggplot2)
```

## Attempt 1 - XLK Model

```{r, message=FALSE}
# 1. Read the CSV files into data frames
data <- read_csv("XLK dataset.csv")

data$Date <- as.Date(data$Date, format("%m/%d/%Y"))
data$Date <- as.numeric(data$Date)

# 2. Split the dataset into training and testing subsets
training_data <- data[1:5884, ]
testing_data <- data[5885:6134, ]

# Train Model using linear regression model ('.' indicates all other variables will be used as predictors)
model <- lm(Close ~ ., data = training_data)

predictions <- predict(model, newdata = testing_data)

# Evaluate performance using Root Mean Square Error
rmse <- sqrt(mean((testing_data$Close - predictions)^2))
cat("Root Mean Square Error:", rmse)

# Plot
ggplot(testing_data, aes(Date, Close)) +
  geom_point(aes(col = "Actual Price")) +  # Testing Data points (Actual price values)
  geom_line(aes(y = predictions, col = "Predictions")) +  # Add a line for model predictions
  geom_smooth(method = "lm", aes(col = "Regression Line"), se = FALSE) + # Regression Line
  labs(x = "Time (Days in which Stock Market is Active)", y = "Stock Price", title = "XLK Stock Linear Regression Model Predictions", subtitle = "(In the last 365 Days)") +
  geom_text(aes(label = paste("Root Mean Square Error =", round(rmse, 4)), x = Inf, y = Inf), hjust = 1, vjust = 1, color = "black") + # RMSE Text
  scale_color_manual(name = "Legend", values = c("black", "blue", "yellow"))


  
plot(testing_data$Close, predictions, 
     xlab = "Observed", ylab = "Predicted", 
     main = "Observed vs. Predicted Values",
     col = "black")
# Red "Perfect" Line
abline(0, 1, col = "red")
```


## EXAMPLE: XLK Model Stochastic Differential Equation Model (SDE)

```{r, message = FALSE, warning=FALSE}
# 1. Read the CSV files into data frames
data <- read_csv("XLK dataset.csv")
data <- select(data, Close)

# Set the last 50 days for testing and all the other days for training
testing <- data[6084:6134, ]
training <- data[5500:6083, ]
training.ts = ts(training)
plot(training.ts, main = "Stock Prices for XLK", ylab = "Price", xlab = "Time (Days)", col = "blue")

# Set up initial value
S_0 <-  testing[1, ]

# Convert testing data to a vector
testing_vector <- as.vector(testing$Close)
training_vector <- as.vector(training$Close)

# Create drift and diffusion/volatility equations (they are characteristics or features of the data that may need to be accounted for when building regression models, particularly for time series data analysis)
d <- expression(theta[1]*x) # Expression for drift term
s <- expression(theta[2]*x) # Expression for volatility term

# PARAMETER ESTIMATION:

#Pseudocode for estimating drift parameter:
drift_func = function(S, lag=1) { # S = stock value
  N = length(S) # Number of sample returns
  
  # set condition for lag difference
  if (N < 1 + lag) {
    stop("S must be greater than 2 + lag")
  }
  
  ct = S[(1+lag):N] # define the next stock value
  pt = S[1:(N-lag)] # define the current stock value
  t = 1 # time horizon (daily)
  dt = t/N # change in time
  
  stk.R = (ct-pt)/pt
  mu_hat = sum(stk.R)/(N*dt)
  mu_hat
}

drift_func(training.ts) # drift estimate

# Pseudocose for estimating volatility parameter:
volt_func = function(S, lag=1) {
  N = length(S)
  
  if (N < 1 + lag) {
    stop("S must be greater than 2 + lag")
  }
  
  ct = S[(1+lag):N]
  pt = S[1:(N-lag)]
  diff = ct - pt # difference between next stock value and current stock value
  
  tt = 1
  dt = tt/N
  
  stk.R = (ct-pt)/pt
  mu_hat = mean(stk.R)
  sigma_hat_sq = sum((stk.R - mu_hat)^2) / ((N - 1) * dt)
  sigma_hat = sqrt(sigma_hat_sq)
  sigma_hat
}

volt_func(training.ts) # volatility estimate

# Assign estimated values to defined objects
drift = drift_func(training.ts)
diffusion = volt_func(training.ts)

# Create drift and diffusion equations from the estimates
d = eval(substitute(expression(drift * x), list(drift = drift)))
s = eval(substitute(expression(diffusion * x) , list(diffusion = diffusion)))

# Number of simulation
n_sim = 1000
pred_x = rep(0,50)

# all_x is used to store all simulated values
# the standard deviation for the confidence interval
all_x = data.frame()

library(Sim.DiffProc)
for (i in 1:n_sim) {
  # Create a hew random seed for each simulation
  rand = as.integer(1000 * runif(1))
  set.seed(rand)

  # Simulate the SDE using Euler method for 50 days into future
  X = snssde1d(N=50, x0=207.35, Dt = 1/6037, drift=d, diffusion=s, method="euler", M=1) #change 207.35 to S_0 after you figure out how to transform the dataset into a vector
  
  pred_x = pred_x + (X$X / 1000)
  all_x = rbind(all_x, as.numeric(X$X))
}

mean_x = pred_x / n_sim # mean value
  
sd_x = sapply(all_x, sd) # standard deviations value
  
# Comparing actual vs predicted values
data.frame(testing, pred_x)
  
# Mean Absolute Percentage Error (MAPE)
mape_func = function(a_val, p_val) { #a_val - actual value, p_val - predicted value
  (1/length(a_val)) * sum(abs((a_val - p_val) / a_val)) * 100
}
mape_func(testing_vector, pred_x)
  
# Create upper and lower confidence bounds (95%)
upper = pred_x + 1.96 * sd_x
lower = pred_x - 1.96 * sd_x
c_int = data.frame(lower,upper)
c_int

# Plot
library(ggplot2)
p = ggplot()
p = p + geom_line(aes(x = 5500:6083, y = training_vector, color="Original Data"))
p = p + geom_line(aes(x = 6084:6134, y = testing_vector, color="Original Data TEST"))
p = p + geom_line(aes(x = 6084:6134, y = pred_x, color="Predicted"))
p = p + labs(x = "Time (Days)", y = "Stock Price", title = "XLK Stock Price", subtitle = "next 50 days")
p = p + geom_ribbon(aes(x=c(6084:6134), y = pred_x, ymin=lower, ymax=upper), fill = "gray", alpha = 0.5)
p
```


## EXAMPLE: Simple ML Model
```{r}
# Load necessary libraries
library(ggplot2)
library(caret)

# 1. EXTRACT FEATURES
# Load the mtcars dataset
data(mtcars)

# Explore the structure of the dataset
str(mtcars)

# Check for missing values
sum(is.na(mtcars))

#2. SPLIT DATASET
# Split the data into training and testing sets
set.seed(123)  # Set seed for reproducibility
index <- createDataPartition(mtcars$mpg, p = 2/3, list = FALSE)
train_data <- mtcars[index, ]
test_data <- mtcars[-index, ]

#3. TRAIN MODEL
# Train a simple linear regression model
lm_model <- lm(mpg ~ ., data = train_data)

# Make predictions on the testing data
predictions <- predict(lm_model, newdata = test_data)

#4. EVALUATE PERFORMANCE
# Evaluate model performance
rmse <- sqrt(mean((test_data$mpg - predictions)^2))
cat("Root Mean Squared Error:", rmse)

plotdata <- data.frame(Observed = test_data$mpg, Predicted = predictions)

# Visualize actual vs. predicted values
ggplot(plotdata, aes(x = Observed, y = Predicted)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(x = "Observed MPG", y = "Predicted MPG", title = "Observed vs. Predicted MPG")

```
